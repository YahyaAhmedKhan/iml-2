{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2  # Choose an appropriate scoring function for your data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_orig = pd.read_csv('train.csv')\n",
    "df_test_orig = pd.read_csv('test.csv')\n",
    "\n",
    "print(df_train_orig.shape)\n",
    "print(df_test_orig.shape)\n",
    "\n",
    "df_train = df_train_orig.copy()\n",
    "df_test = df_test_orig.copy()\n",
    "target_col = 'price_doc'\n",
    "row_id_col = 'row ID'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181507, 274) \n",
      " (77789, 274)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Label encode the 'sub_area' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['sub_area'] = label_encoder.fit_transform(df_train['sub_area'])\n",
    "df_test['sub_area'] = label_encoder.transform(df_test['sub_area'])\n",
    "\n",
    "X_train = pd.get_dummies(df_train.drop(columns=[target_col]), drop_first=True)\n",
    "X_test = pd.get_dummies(df_test, drop_first=True)\n",
    "\n",
    "row_ids = df_test['row ID']\n",
    "X_test.drop(['row ID'], axis=1, inplace=True)\n",
    "print(X_train.shape, '\\n', X_test.shape)\n",
    "X = pd.get_dummies(df_train.drop(columns=[target_col]), drop_first=True)\n",
    "y = df_train[target_col]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30124      535\n",
       "134681    1649\n",
       "105079    1524\n",
       "131181     507\n",
       "28846     1538\n",
       "          ... \n",
       "119879     463\n",
       "103694    1456\n",
       "131932     496\n",
       "146867     618\n",
       "121958     626\n",
       "Name: sub_area, Length: 172431, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=8, min_samples_leaf=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=8, min_samples_leaf=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=8, min_samples_leaf=5, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the decision tree model for feature selection\n",
    "tree = DecisionTreeRegressor(random_state=42, max_depth=8, min_samples_leaf=5)\n",
    "\n",
    "# Fit the decision tree model on the data\n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mosque_count_500', 'culture_objects_top_25_raion', 'full_sq',\n",
       "       'cafe_count_5000_price_high', 'cafe_count_3000',\n",
       "       'culture_objects_top_25_yes', 'cafe_count_3000_price_2500',\n",
       "       'sport_count_3000', 'sport_count_2000', 'university_km',\n",
       "       'raion_build_count_with_builddate_info', 'indust_part', 'life_sq',\n",
       "       'build_count_1971-1995', 'workplaces_km', 'cemetery_km',\n",
       "       'cafe_count_3000_price_high', 'build_count_1921-1945',\n",
       "       'cafe_count_2000_price_4000', 'ID_railroad_station_avto',\n",
       "       'additional_education_raion', 'preschool_km',\n",
       "       'cafe_count_2000_na_price', '7_14_male', 'young_all',\n",
       "       'cafe_count_500_price_high', 'sadovoe_km', 'cafe_count_1500_na_price',\n",
       "       'church_count_1500', 'build_count_after_1995', 'railroad_km',\n",
       "       'shopping_centers_km', 'trc_count_1000', 'hospice_morgue_km',\n",
       "       'exhibition_km', 'market_count_5000', 'mosque_count_2000',\n",
       "       'power_transmission_line_km', 'cafe_sum_3000_min_price_avg',\n",
       "       '16_29_male', 'catering_km', 'office_count_500', 'fitness_km',\n",
       "       'green_zone_part', '0_17_male', 'build_count_wood', 'office_sqm_2000',\n",
       "       'female_f', 'cafe_count_1000', 'metro_min_walk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get feature importances from the decision tree model\n",
    "feature_importances = tree.feature_importances_\n",
    "\n",
    "# Get indices of top 50 features based on importance\n",
    "top_50_indices = feature_importances.argsort()[-50:][::-1]\n",
    "\n",
    "# Get the corresponding column names\n",
    "selected_col = X_train.columns[top_50_indices]\n",
    "selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172431, 50) (9076, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Filter the training and validation data with the selected features\n",
    "X_train_selected = X_train[selected_col]\n",
    "X_val_selected = X_val[selected_col]\n",
    "print(X_train_selected.shape, X_val_selected.shape)\n",
    "# Scale the selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_val_scaled = scaler.transform(X_val_selected)\n",
    "\n",
    "# Train the linear regression model on the selected features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with selected features: 13874738.00877532\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_val_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "print(\"RMSE with selected features:\", rmse)\n",
    "\n",
    "# Filter the test data with the selected features\n",
    "X_test_selected = X_test[selected_col]\n",
    "\n",
    "# Scale the selected features\n",
    "X_test_scaled = scaler.transform(X_test_selected)  # Assuming 'scaler' is the trained StandardScaler\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame with 'row ID' and predictions\n",
    "result_df = pd.DataFrame({'row ID': row_ids, 'price_doc': test_predictions})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "result_df.to_csv('predictions3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 15\n",
      "RMSE with top 15 variance selected features: 14567619.343945056\n",
      "Number of features selected: 30\n",
      "RMSE with top 30 variance selected features: 13951382.398785004\n",
      "Number of features selected: 45\n",
      "RMSE with top 45 variance selected features: 13753493.101001613\n",
      "Number of features selected: 60\n",
      "RMSE with top 60 variance selected features: 13632182.531351903\n",
      "Number of features selected: 75\n",
      "RMSE with top 75 variance selected features: 13573313.71213994\n",
      "Number of features selected: 90\n",
      "RMSE with top 90 variance selected features: 13520218.5490231\n",
      "Number of features selected: 105\n",
      "RMSE with top 105 variance selected features: 13489149.853239339\n",
      "Number of features selected: 120\n",
      "RMSE with top 120 variance selected features: 13472756.303250194\n",
      "Number of features selected: 135\n",
      "RMSE with top 135 variance selected features: 13455569.370513437\n",
      "Number of features selected: 150\n",
      "RMSE with top 150 variance selected features: 13444299.5223306\n",
      "Number of features selected: 165\n",
      "RMSE with top 165 variance selected features: 13450189.516994853\n",
      "Number of features selected: 180\n",
      "RMSE with top 180 variance selected features: 13433714.983132206\n",
      "Number of features selected: 195\n",
      "RMSE with top 195 variance selected features: 13426109.365134537\n",
      "Number of features selected: 210\n",
      "RMSE with top 210 variance selected features: 13400046.455623103\n",
      "Number of features selected: 225\n",
      "RMSE with top 225 variance selected features: 13365687.972315153\n",
      "Number of features selected: 240\n",
      "RMSE with top 240 variance selected features: 13341194.264572069\n",
      "Number of features selected: 255\n",
      "RMSE with top 255 variance selected features: 13337530.911706455\n",
      "Number of features selected: 270\n",
      "RMSE with top 270 variance selected features: 13353284.889142795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the training and test data\n",
    "df_train_orig = pd.read_csv('train.csv')\n",
    "df_test_orig = pd.read_csv('test.csv')\n",
    "\n",
    "# Make a copy of the original data\n",
    "df_train = df_train_orig.copy()\n",
    "df_test = df_test_orig.copy()\n",
    "target_col = 'price_doc'\n",
    "row_id_col = 'row ID'\n",
    "\n",
    "# Label encode the 'sub_area' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['sub_area'] = label_encoder.fit_transform(df_train['sub_area'])\n",
    "df_test['sub_area'] = label_encoder.transform(df_test['sub_area'])\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "X_train = pd.get_dummies(df_train.drop(columns=[target_col]), drop_first=True)\n",
    "X_test = pd.get_dummies(df_test, drop_first=True)\n",
    "\n",
    "# Extract the 'row ID' column for later use and remove it from X_test\n",
    "row_ids = df_test['row ID']\n",
    "X_test.drop(['row ID'], axis=1, inplace=True)\n",
    "\n",
    "# Extract the target variable and create a feature matrix\n",
    "X = pd.get_dummies(df_train.drop(columns=[target_col]), drop_first=True)\n",
    "y = df_train[target_col]\n",
    "\n",
    "# Scale the values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Compute variances of features\n",
    "variances = np.var(X_train, axis=0)\n",
    "\n",
    "# Iterate over different values of k\n",
    "for k in range(15, 271, 15):\n",
    "    # Get the indices of the top k features with the highest variances\n",
    "    top_k_indices = np.argsort(variances)[-k:]\n",
    "\n",
    "    # Select the top k features\n",
    "    X_train_selected = X_train[:, top_k_indices]\n",
    "    X_val_selected = X_val[:, top_k_indices]\n",
    "\n",
    "    print(\"Number of features selected:\", X_train_selected.shape[1])\n",
    "\n",
    "    # Train the linear regression model on the selected features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(X_val_selected)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "    print(f\"RMSE with top {k} variance selected features:\", rmse)\n",
    "\n",
    "    # Transform the test data using the same feature selection\n",
    "    X_test_selected = X_test[:, top_k_indices]\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    test_predictions = model.predict(X_test_selected)\n",
    "\n",
    "    # Create a DataFrame with 'row ID' and predictions\n",
    "    result_df = pd.DataFrame({'row ID': row_ids, 'price_doc': test_predictions})\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    result_df.to_csv(f'predictions_top_{k}_variance_features.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
