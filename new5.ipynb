{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training and test data\n",
    "df_train_orig = pd.read_csv('train.csv')\n",
    "df_test_orig = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a copy of the original data\n",
    "df_train = df_train_orig.copy()\n",
    "df_test = df_test_orig.copy()\n",
    "target_col = 'price_doc'\n",
    "row_id_col = 'row ID'\n",
    "\n",
    "row_ids = df_test['row ID']\n",
    "df_test.drop(['row ID'], axis=1, inplace=True)\n",
    "\n",
    "numeric_col = df_test.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "categorical_cols = df_test.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Label encode the \"sub_area\" column\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['sub_area'] = label_encoder.fit_transform(df_train['sub_area'])\n",
    "df_test['sub_area'] = label_encoder.transform(df_test['sub_area'])\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "X_train = pd.get_dummies(df_train.drop(columns=[target_col]), drop_first=True)\n",
    "y = df_train[target_col]\n",
    "\n",
    "X_test = pd.get_dummies(df_test, drop_first=True)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[numeric_col] = scaler.fit_transform(X_train[numeric_col])\n",
    "X_test[numeric_col] = scaler.transform(X_test[numeric_col])\n",
    "\n",
    "print('X_train_scaled shape:', X_train.shape)\n",
    "print('X_test_scaled shape:', X_test.shape)\n",
    "\n",
    "all_columns = X_train.columns.tolist()\n",
    "\n",
    "# Get the non-numeric columns by subtracting numeric_col from all_columns\n",
    "non_numeric_columns = [col for col in all_columns if col not in numeric_col]\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Use a Decision Tree Regressor to get the 100 most important features\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=8, random_state=42)\n",
    "tree_regressor.fit(X_train, y)\n",
    "importances = tree_regressor.feature_importances_\n",
    "\n",
    "\n",
    "# Get indices of the top 100 features\n",
    "top_100_feature_indices = np.argsort(importances)[-150:]\n",
    "\n",
    "# Select the top 100 features\n",
    "X_train = X_train.iloc[:, top_100_feature_indices]\n",
    "X_test = X_test.iloc[:, top_100_feature_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_regression, k=100)\n",
    "\n",
    "X_train = selector.fit_transform(X_train,y)\n",
    "\n",
    "\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "print('X_train_scaled shape:', X_train.shape)\n",
    "print('X_test_scaled shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print('X_train_pca shape:', X_train.shape)\n",
    "print('X_test_pca shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1\n",
    "\n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use Forward Selection to get the first 10 best features\n",
    "selector = SequentialFeatureSelector(estimator=LinearRegression(), n_features_to_select=10)\n",
    "selector.fit(X_train, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = selector.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Select the first 10 best features\n",
    "# X_train = X_train.iloc[:, selected_feature_indices]\n",
    "# X_test = X_test.iloc[:, selected_feature_indices]\n",
    "# Select the first 10 best features\n",
    "X_train = X_train[:, selected_feature_indices]\n",
    "X_test = X_test[:, selected_feature_indices]\n",
    "\n",
    "print('X_train_top10 shape:', X_train.shape)\n",
    "print('X_test_top10 shape:', X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Use Polynomial Features with interaction on the selected features\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "print('X_train_poly shape:', X_train.shape)\n",
    "print('X_test_poly shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Define your model with L2 regularization\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Compile the model with RMSprop optimizer\n",
    "optimizer = RMSprop(learning_rate=0.001)  # You can adjust the learning rate\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[keras.metrics.RootMeanSquaredError(), 'mae'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y, epochs=15, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=custom_optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), 'mae'])\n",
    "\n",
    "model.fit(X_train, y, epochs=15, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import Adam, legacy\n",
    "import math\n",
    "\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "#model.add(Dropout(0.2))  # Apply dropout with a rate of 0.2\n",
    "model.add(Dense(64, activation='relu'))#sigmoid\n",
    "# model.add(Dense(64, activation='relu'))#sigmoid\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Add regularizers to the dense layers\n",
    "model.layers[1].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "model.layers[2].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "#model.layers[3].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "\n",
    "opt = legacy.Adam(learning_rate=0.00021)  \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['RootMeanSquaredError'])\n",
    "#apply early stoppping\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "#apply model checkpoint\n",
    "\n",
    "#fit the keras model on the dataset\n",
    "model.fit(X_train, y, epochs=50, batch_size=63, validation_split=0.2, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Create a DataFrame with 'row ID' and predictions\n",
    "result_df = pd.DataFrame({'row ID': row_ids, 'price_doc': test_predictions})\n",
    "\n",
    "result_df.to_csv('predictions_55.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shahood\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the training and test data\n",
    "df_train_orig = pd.read_csv('train.csv')\n",
    "df_test_orig = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a copy of the original data\n",
    "df_train = df_train_orig.copy()\n",
    "df_test = df_test_orig.copy()\n",
    "target_col = 'price_doc'\n",
    "row_id_col = 'row ID'\n",
    "\n",
    "row_ids = df_test['row ID']\n",
    "df_test.drop(['row ID'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X_train = df_train.drop(columns=[target_col])\n",
    "y = df_train[target_col]\n",
    "\n",
    "\n",
    "\n",
    "X_test = df_test\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_exclude = [\n",
    "    'ID_metro', \n",
    "    'ID_railroad_station_walk', \n",
    "    'ID_bus_terminal', \n",
    "    'cemetery_km', \n",
    "    'power_transmission_line_km', \n",
    "    'big_church_count_500', \n",
    "    'church_count_500', \n",
    "    'mosque_count_500', \n",
    "    'theater_km', \n",
    "    'museum_km'\n",
    "]\n",
    "X_train = X_train.drop(columns=features_to_exclude)\n",
    "X_test = X_test.drop(columns=features_to_exclude)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Define a custom scoring function that returns -log(p-value)\n",
    "def p_value_score(X, y):\n",
    "    _, p_values = f_regression(X, y)\n",
    "    return -np.log(p_values)\n",
    "\n",
    "# Define the number of features you want to select\n",
    "num_features_to_select = 50  # Adjust this number as per your requirement\n",
    "\n",
    "# Initialize SelectKBest with the custom scoring function\n",
    "selector = SelectKBest(score_func=p_value_score, k=num_features_to_select)\n",
    "\n",
    "# Fit and transform X_train to select the best features\n",
    "X_train_selected = selector.fit_transform(X_train, y)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_train.columns[selected_feature_indices]\n",
    "\n",
    "# Transform X_test to keep only the selected features\n",
    "X_test_selected = X_test.iloc[:, selected_feature_indices]\n",
    "\n",
    "print('Selected Features:', selected_feature_names)\n",
    "print('X_train_selected shape:', X_train_selected.shape)\n",
    "print('X_test_selected shape:', X_test_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_selected\n",
    "X_test = X_test_selected\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['sub_area'])\n",
    "X_test = X_test.drop(columns=['sub_area'])\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "#'''\n",
    "# Apply label encoding to each categorical column\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fill missing values with a placeholder string\n",
    "    #X_train[col] = X_train[col].fillna('Missing')\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    #X_test[col] = X_test[col].fillna('Missing')\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_regressor = DecisionTreeRegressor(random_state=42, max_depth=6)\n",
    "dt_regressor.fit(X_train, y)\n",
    "\n",
    "# Calculate Feature Importance\n",
    "feature_importance = dt_regressor.feature_importances_\n",
    "\n",
    "# Select Important Features\n",
    "num_features_to_keep = 50\n",
    "top_feature_indices = feature_importance.argsort()[-num_features_to_keep:][::-1]\n",
    "# X_train = X_train.iloc[:, top_feature_indices]\n",
    "# X_test = X_test.iloc[:, top_feature_indices]\n",
    "X_train = X_train[:, top_feature_indices]\n",
    "X_test = X_test[:, top_feature_indices]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42, max_depth=4)\n",
    "\n",
    "rfecv = RFECV(estimator=dt_regressor, step=1, scoring='neg_mean_squared_error', min_features_to_select=10)\n",
    "# Adjust the 'min_features_to_select' parameter to specify the number of features you want to select (in this case, 10).\n",
    "\n",
    "# Fit the RFECV selector to the training data\n",
    "rfecv.fit(X_train, y)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = rfecv.support_\n",
    "\n",
    "# Select the important features from the original dataset\n",
    "X_train = X_train[:, selected_feature_indices]\n",
    "X_test = X_test[:, selected_feature_indices]\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Define a threshold for variance (adjust as needed)\n",
    "variance_threshold = 1\n",
    "# Initialize the Variancehreshold selector\n",
    "selector = VarianceThreshold(threshold=variance_threshold)\n",
    "\n",
    "# Fit and transform the selector on your selected feature matrix\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Forward Feature Selection\n",
    "sfs = SequentialFeatureSelector(lr, n_features_to_select=9, direction='forward', scoring='neg_mean_squared_error', n_jobs=3)\n",
    "sfs.fit(X_train, y)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_features = sfs.get_support()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_selected\n",
    "X_test = X_test_selected\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, selected_features]\n",
    "X_test = X_test[:, selected_features]\n",
    "\n",
    "# Check the shape of the resulting X_train and X_test\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "print('X_train_poly shape:', X_train.shape)\n",
    "print('X_test_poly shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform PCA to reduce dimensionality to 240 components\n",
    "n_components = 30\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Now X_train_pca and X_test_pca contain the top 240 principal components\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(max_depth=8, random_state=42, min_samples_leaf=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create an XGBoost regressor\n",
    "model = xgb.XGBRegressor(n_estimators=30, max_depth=10, random_state=42, learning_rate=0.1, min_child_weight=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Randomforest regressor\n",
    "model = RandomForestRegressor(n_estimators=3, max_depth=8, random_state=42, min_samples_leaf=10, n_jobs=3, verbose=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 21793310.1662866\ttotal: 114ms\tremaining: 34.2s\n",
      "1:\tlearn: 21658379.9861791\ttotal: 195ms\tremaining: 29.1s\n",
      "2:\tlearn: 21525303.9207420\ttotal: 279ms\tremaining: 27.6s\n",
      "3:\tlearn: 21394569.7267078\ttotal: 366ms\tremaining: 27.1s\n",
      "4:\tlearn: 21265986.2415824\ttotal: 467ms\tremaining: 27.5s\n",
      "5:\tlearn: 21138870.7112912\ttotal: 558ms\tremaining: 27.3s\n",
      "6:\tlearn: 21013345.5673402\ttotal: 647ms\tremaining: 27.1s\n",
      "7:\tlearn: 20889702.3909247\ttotal: 751ms\tremaining: 27.4s\n",
      "8:\tlearn: 20768206.3332810\ttotal: 841ms\tremaining: 27.2s\n",
      "9:\tlearn: 20646575.4541416\ttotal: 947ms\tremaining: 27.5s\n",
      "10:\tlearn: 20526831.5127730\ttotal: 1.05s\tremaining: 27.5s\n",
      "11:\tlearn: 20409260.8085930\ttotal: 1.14s\tremaining: 27.3s\n",
      "12:\tlearn: 20292537.7539561\ttotal: 1.25s\tremaining: 27.7s\n",
      "13:\tlearn: 20177793.2745035\ttotal: 1.41s\tremaining: 28.8s\n",
      "14:\tlearn: 20066032.5039444\ttotal: 1.49s\tremaining: 28.4s\n",
      "15:\tlearn: 19955479.3524509\ttotal: 1.58s\tremaining: 28.1s\n",
      "16:\tlearn: 19845882.4861403\ttotal: 1.67s\tremaining: 27.8s\n",
      "17:\tlearn: 19737024.4816850\ttotal: 1.75s\tremaining: 27.4s\n",
      "18:\tlearn: 19630825.0208623\ttotal: 1.84s\tremaining: 27.2s\n",
      "19:\tlearn: 19524309.2350408\ttotal: 1.93s\tremaining: 27s\n",
      "20:\tlearn: 19420224.5881893\ttotal: 2.01s\tremaining: 26.7s\n",
      "21:\tlearn: 19318625.5725256\ttotal: 2.1s\tremaining: 26.6s\n",
      "22:\tlearn: 19217044.6641848\ttotal: 2.19s\tremaining: 26.4s\n",
      "23:\tlearn: 19117919.5100485\ttotal: 2.28s\tremaining: 26.2s\n",
      "24:\tlearn: 19020477.4433798\ttotal: 2.37s\tremaining: 26s\n",
      "25:\tlearn: 18924298.9668760\ttotal: 2.45s\tremaining: 25.8s\n",
      "26:\tlearn: 18829356.1224398\ttotal: 2.54s\tremaining: 25.7s\n",
      "27:\tlearn: 18735422.2498617\ttotal: 2.65s\tremaining: 25.8s\n",
      "28:\tlearn: 18643079.7827055\ttotal: 2.74s\tremaining: 25.6s\n",
      "29:\tlearn: 18551348.9413305\ttotal: 2.83s\tremaining: 25.5s\n",
      "30:\tlearn: 18461625.0810313\ttotal: 2.91s\tremaining: 25.3s\n",
      "31:\tlearn: 18372472.2779551\ttotal: 2.99s\tremaining: 25.1s\n",
      "32:\tlearn: 18283948.9996089\ttotal: 3.08s\tremaining: 24.9s\n",
      "33:\tlearn: 18197464.9926730\ttotal: 3.16s\tremaining: 24.7s\n",
      "34:\tlearn: 18112556.3382383\ttotal: 3.24s\tremaining: 24.6s\n",
      "35:\tlearn: 18029268.2504582\ttotal: 3.35s\tremaining: 24.6s\n",
      "36:\tlearn: 17946718.7882538\ttotal: 3.45s\tremaining: 24.5s\n",
      "37:\tlearn: 17865377.3823106\ttotal: 3.54s\tremaining: 24.4s\n",
      "38:\tlearn: 17784405.9777898\ttotal: 3.62s\tremaining: 24.2s\n",
      "39:\tlearn: 17706199.0999124\ttotal: 3.71s\tremaining: 24.1s\n",
      "40:\tlearn: 17627860.4606878\ttotal: 3.79s\tremaining: 23.9s\n",
      "41:\tlearn: 17551256.2345577\ttotal: 3.88s\tremaining: 23.8s\n",
      "42:\tlearn: 17475531.4011579\ttotal: 3.96s\tremaining: 23.7s\n",
      "43:\tlearn: 17400559.6734071\ttotal: 4.05s\tremaining: 23.5s\n",
      "44:\tlearn: 17327368.2194773\ttotal: 4.13s\tremaining: 23.4s\n",
      "45:\tlearn: 17255360.1554617\ttotal: 4.26s\tremaining: 23.5s\n",
      "46:\tlearn: 17183707.4203920\ttotal: 4.35s\tremaining: 23.4s\n",
      "47:\tlearn: 17113208.5365321\ttotal: 4.43s\tremaining: 23.3s\n",
      "48:\tlearn: 17044138.7718805\ttotal: 4.52s\tremaining: 23.1s\n",
      "49:\tlearn: 16976377.5024134\ttotal: 4.6s\tremaining: 23s\n",
      "50:\tlearn: 16908524.6327953\ttotal: 4.69s\tremaining: 22.9s\n",
      "51:\tlearn: 16842493.3566148\ttotal: 4.77s\tremaining: 22.8s\n",
      "52:\tlearn: 16777986.3816637\ttotal: 4.86s\tremaining: 22.6s\n",
      "53:\tlearn: 16714659.8705006\ttotal: 4.94s\tremaining: 22.5s\n",
      "54:\tlearn: 16651516.6132834\ttotal: 5.03s\tremaining: 22.4s\n",
      "55:\tlearn: 16589707.7862499\ttotal: 5.11s\tremaining: 22.3s\n",
      "56:\tlearn: 16528063.9496287\ttotal: 5.19s\tremaining: 22.1s\n",
      "57:\tlearn: 16468239.0550832\ttotal: 5.3s\tremaining: 22.1s\n",
      "58:\tlearn: 16409167.9667256\ttotal: 5.41s\tremaining: 22.1s\n",
      "59:\tlearn: 16350905.9585651\ttotal: 5.57s\tremaining: 22.3s\n",
      "60:\tlearn: 16294003.5099953\ttotal: 5.66s\tremaining: 22.2s\n",
      "61:\tlearn: 16237958.5265122\ttotal: 5.74s\tremaining: 22s\n",
      "62:\tlearn: 16182648.6975213\ttotal: 5.83s\tremaining: 21.9s\n",
      "63:\tlearn: 16128073.0095380\ttotal: 5.93s\tremaining: 21.9s\n",
      "64:\tlearn: 16074247.0522480\ttotal: 6.03s\tremaining: 21.8s\n",
      "65:\tlearn: 16020870.2097019\ttotal: 6.12s\tremaining: 21.7s\n",
      "66:\tlearn: 15968558.4320305\ttotal: 6.2s\tremaining: 21.6s\n",
      "67:\tlearn: 15917510.4763877\ttotal: 6.28s\tremaining: 21.4s\n",
      "68:\tlearn: 15867448.6239387\ttotal: 6.37s\tremaining: 21.3s\n",
      "69:\tlearn: 15818122.4824892\ttotal: 6.46s\tremaining: 21.2s\n",
      "70:\tlearn: 15769017.7150613\ttotal: 6.54s\tremaining: 21.1s\n",
      "71:\tlearn: 15721475.8014055\ttotal: 6.62s\tremaining: 21s\n",
      "72:\tlearn: 15674578.5373328\ttotal: 6.71s\tremaining: 20.9s\n",
      "73:\tlearn: 15628122.9909861\ttotal: 6.79s\tremaining: 20.7s\n",
      "74:\tlearn: 15582393.0134490\ttotal: 6.87s\tremaining: 20.6s\n",
      "75:\tlearn: 15537677.5181077\ttotal: 6.96s\tremaining: 20.5s\n",
      "76:\tlearn: 15493364.1876311\ttotal: 7.04s\tremaining: 20.4s\n",
      "77:\tlearn: 15449505.2551662\ttotal: 7.12s\tremaining: 20.3s\n",
      "78:\tlearn: 15406326.6725295\ttotal: 7.21s\tremaining: 20.2s\n",
      "79:\tlearn: 15364230.8937946\ttotal: 7.29s\tremaining: 20s\n",
      "80:\tlearn: 15322753.8398091\ttotal: 7.37s\tremaining: 19.9s\n",
      "81:\tlearn: 15281450.6450179\ttotal: 7.46s\tremaining: 19.8s\n",
      "82:\tlearn: 15241216.1348278\ttotal: 7.54s\tremaining: 19.7s\n",
      "83:\tlearn: 15201425.6664384\ttotal: 7.63s\tremaining: 19.6s\n",
      "84:\tlearn: 15162383.0073284\ttotal: 7.71s\tremaining: 19.5s\n",
      "85:\tlearn: 15124048.3516068\ttotal: 7.8s\tremaining: 19.4s\n",
      "86:\tlearn: 15086115.9046858\ttotal: 7.88s\tremaining: 19.3s\n",
      "87:\tlearn: 15049007.1647664\ttotal: 7.97s\tremaining: 19.2s\n",
      "88:\tlearn: 15012356.0489655\ttotal: 8.05s\tremaining: 19.1s\n",
      "89:\tlearn: 14976320.8375661\ttotal: 8.14s\tremaining: 19s\n",
      "90:\tlearn: 14941047.9231011\ttotal: 8.22s\tremaining: 18.9s\n",
      "91:\tlearn: 14905967.0211257\ttotal: 8.31s\tremaining: 18.8s\n",
      "92:\tlearn: 14871211.3930007\ttotal: 8.39s\tremaining: 18.7s\n",
      "93:\tlearn: 14836985.7979790\ttotal: 8.48s\tremaining: 18.6s\n",
      "94:\tlearn: 14803869.0731899\ttotal: 8.57s\tremaining: 18.5s\n",
      "95:\tlearn: 14772075.7054333\ttotal: 8.65s\tremaining: 18.4s\n",
      "96:\tlearn: 14740239.2663127\ttotal: 8.74s\tremaining: 18.3s\n",
      "97:\tlearn: 14708876.1704219\ttotal: 8.82s\tremaining: 18.2s\n",
      "98:\tlearn: 14677701.8086165\ttotal: 8.9s\tremaining: 18.1s\n",
      "99:\tlearn: 14647485.8555190\ttotal: 8.98s\tremaining: 18s\n",
      "100:\tlearn: 14617561.5622900\ttotal: 9.07s\tremaining: 17.9s\n",
      "101:\tlearn: 14588202.6230948\ttotal: 9.16s\tremaining: 17.8s\n",
      "102:\tlearn: 14559744.7358195\ttotal: 9.25s\tremaining: 17.7s\n",
      "103:\tlearn: 14531419.2474187\ttotal: 9.34s\tremaining: 17.6s\n",
      "104:\tlearn: 14504558.7006864\ttotal: 9.43s\tremaining: 17.5s\n",
      "105:\tlearn: 14476967.8323055\ttotal: 9.55s\tremaining: 17.5s\n",
      "106:\tlearn: 14450246.3922406\ttotal: 9.65s\tremaining: 17.4s\n",
      "107:\tlearn: 14423328.9418961\ttotal: 9.74s\tremaining: 17.3s\n",
      "108:\tlearn: 14397307.7069288\ttotal: 9.83s\tremaining: 17.2s\n",
      "109:\tlearn: 14371392.1988239\ttotal: 9.92s\tremaining: 17.1s\n",
      "110:\tlearn: 14346324.2255347\ttotal: 10s\tremaining: 17s\n",
      "111:\tlearn: 14321995.3569281\ttotal: 10.1s\tremaining: 17s\n",
      "112:\tlearn: 14297763.0639585\ttotal: 10.2s\tremaining: 16.9s\n",
      "113:\tlearn: 14273725.5323806\ttotal: 10.3s\tremaining: 16.8s\n",
      "114:\tlearn: 14250263.8675432\ttotal: 10.4s\tremaining: 16.7s\n",
      "115:\tlearn: 14227352.6711544\ttotal: 10.5s\tremaining: 16.6s\n",
      "116:\tlearn: 14204915.2545683\ttotal: 10.6s\tremaining: 16.5s\n",
      "117:\tlearn: 14182596.2570560\ttotal: 10.8s\tremaining: 16.6s\n",
      "118:\tlearn: 14160688.9719270\ttotal: 10.9s\tremaining: 16.5s\n",
      "119:\tlearn: 14139159.2744079\ttotal: 11s\tremaining: 16.5s\n",
      "120:\tlearn: 14118187.1234266\ttotal: 11.1s\tremaining: 16.4s\n",
      "121:\tlearn: 14097429.6198196\ttotal: 11.2s\tremaining: 16.3s\n",
      "122:\tlearn: 14076379.3517204\ttotal: 11.2s\tremaining: 16.2s\n",
      "123:\tlearn: 14055767.6074805\ttotal: 11.3s\tremaining: 16.1s\n",
      "124:\tlearn: 14036119.0574804\ttotal: 11.4s\tremaining: 16s\n",
      "125:\tlearn: 14016103.8158548\ttotal: 11.6s\tremaining: 16s\n",
      "126:\tlearn: 13997109.7797843\ttotal: 11.8s\tremaining: 16.1s\n",
      "127:\tlearn: 13978428.2996293\ttotal: 12s\tremaining: 16.1s\n",
      "128:\tlearn: 13960461.1438027\ttotal: 12.1s\tremaining: 16s\n",
      "129:\tlearn: 13941769.7684281\ttotal: 12.2s\tremaining: 15.9s\n",
      "130:\tlearn: 13923573.8656465\ttotal: 12.3s\tremaining: 15.8s\n",
      "131:\tlearn: 13905661.6067389\ttotal: 12.4s\tremaining: 15.7s\n",
      "132:\tlearn: 13887968.3921876\ttotal: 12.5s\tremaining: 15.6s\n",
      "133:\tlearn: 13870360.9181611\ttotal: 12.6s\tremaining: 15.5s\n",
      "134:\tlearn: 13853185.2824659\ttotal: 12.7s\tremaining: 15.5s\n",
      "135:\tlearn: 13836864.6608987\ttotal: 12.8s\tremaining: 15.4s\n",
      "136:\tlearn: 13821078.2352562\ttotal: 12.9s\tremaining: 15.3s\n",
      "137:\tlearn: 13805272.7164085\ttotal: 13s\tremaining: 15.3s\n",
      "138:\tlearn: 13789375.0871862\ttotal: 13.1s\tremaining: 15.2s\n",
      "139:\tlearn: 13773449.0791319\ttotal: 13.2s\tremaining: 15.1s\n",
      "140:\tlearn: 13758123.8757531\ttotal: 13.3s\tremaining: 15s\n",
      "141:\tlearn: 13743153.1385563\ttotal: 13.4s\tremaining: 14.9s\n",
      "142:\tlearn: 13728265.8486849\ttotal: 13.5s\tremaining: 14.8s\n",
      "143:\tlearn: 13713628.5993104\ttotal: 13.6s\tremaining: 14.8s\n",
      "144:\tlearn: 13699265.1174210\ttotal: 13.7s\tremaining: 14.7s\n",
      "145:\tlearn: 13685358.2983327\ttotal: 13.8s\tremaining: 14.6s\n",
      "146:\tlearn: 13671376.7350530\ttotal: 13.9s\tremaining: 14.5s\n",
      "147:\tlearn: 13657771.9533825\ttotal: 14s\tremaining: 14.4s\n",
      "148:\tlearn: 13645045.1081386\ttotal: 14.1s\tremaining: 14.3s\n",
      "149:\tlearn: 13631937.3592439\ttotal: 14.2s\tremaining: 14.2s\n",
      "150:\tlearn: 13618994.5655352\ttotal: 14.3s\tremaining: 14.1s\n",
      "151:\tlearn: 13606866.7215469\ttotal: 14.4s\tremaining: 14s\n",
      "152:\tlearn: 13594612.8040156\ttotal: 14.5s\tremaining: 13.9s\n",
      "153:\tlearn: 13582095.9407321\ttotal: 14.6s\tremaining: 13.8s\n",
      "154:\tlearn: 13569993.1737714\ttotal: 14.7s\tremaining: 13.8s\n",
      "155:\tlearn: 13558160.6758504\ttotal: 14.8s\tremaining: 13.7s\n",
      "156:\tlearn: 13546593.0748906\ttotal: 14.9s\tremaining: 13.6s\n",
      "157:\tlearn: 13535025.4101467\ttotal: 15s\tremaining: 13.5s\n",
      "158:\tlearn: 13523602.2196914\ttotal: 15.1s\tremaining: 13.4s\n",
      "159:\tlearn: 13512921.5187178\ttotal: 15.2s\tremaining: 13.3s\n",
      "160:\tlearn: 13501938.3284183\ttotal: 15.3s\tremaining: 13.2s\n",
      "161:\tlearn: 13491009.5968296\ttotal: 15.4s\tremaining: 13.1s\n",
      "162:\tlearn: 13480402.2442098\ttotal: 15.5s\tremaining: 13s\n",
      "163:\tlearn: 13469975.5908631\ttotal: 15.6s\tremaining: 13s\n",
      "164:\tlearn: 13459729.2312126\ttotal: 15.7s\tremaining: 12.9s\n",
      "165:\tlearn: 13449575.8294179\ttotal: 15.8s\tremaining: 12.8s\n",
      "166:\tlearn: 13440085.7057859\ttotal: 15.9s\tremaining: 12.7s\n",
      "167:\tlearn: 13429835.9467062\ttotal: 16s\tremaining: 12.6s\n",
      "168:\tlearn: 13420125.0341988\ttotal: 16.1s\tremaining: 12.5s\n",
      "169:\tlearn: 13410665.6591900\ttotal: 16.2s\tremaining: 12.4s\n",
      "170:\tlearn: 13401449.6707108\ttotal: 16.3s\tremaining: 12.3s\n",
      "171:\tlearn: 13392359.0103796\ttotal: 16.4s\tremaining: 12.2s\n",
      "172:\tlearn: 13383359.9908301\ttotal: 16.5s\tremaining: 12.1s\n",
      "173:\tlearn: 13374063.5786247\ttotal: 16.6s\tremaining: 12s\n",
      "174:\tlearn: 13365206.9373684\ttotal: 16.7s\tremaining: 11.9s\n",
      "175:\tlearn: 13356734.3251047\ttotal: 16.8s\tremaining: 11.9s\n",
      "176:\tlearn: 13348537.7716002\ttotal: 16.9s\tremaining: 11.8s\n",
      "177:\tlearn: 13340372.8068636\ttotal: 17s\tremaining: 11.7s\n",
      "178:\tlearn: 13331970.1816591\ttotal: 17.1s\tremaining: 11.6s\n",
      "179:\tlearn: 13324016.9732870\ttotal: 17.2s\tremaining: 11.5s\n",
      "180:\tlearn: 13315639.3859614\ttotal: 17.3s\tremaining: 11.4s\n",
      "181:\tlearn: 13307813.7287706\ttotal: 17.4s\tremaining: 11.3s\n",
      "182:\tlearn: 13300526.4970992\ttotal: 17.5s\tremaining: 11.2s\n",
      "183:\tlearn: 13293032.4664523\ttotal: 17.6s\tremaining: 11.1s\n",
      "184:\tlearn: 13285693.0318245\ttotal: 17.7s\tremaining: 11s\n",
      "185:\tlearn: 13278731.5054496\ttotal: 17.8s\tremaining: 10.9s\n",
      "186:\tlearn: 13271896.8138869\ttotal: 17.9s\tremaining: 10.8s\n",
      "187:\tlearn: 13264744.4971928\ttotal: 18s\tremaining: 10.7s\n",
      "188:\tlearn: 13257672.9804173\ttotal: 18.1s\tremaining: 10.6s\n",
      "189:\tlearn: 13250575.4197899\ttotal: 18.2s\tremaining: 10.6s\n",
      "190:\tlearn: 13244083.8960508\ttotal: 18.3s\tremaining: 10.5s\n",
      "191:\tlearn: 13237804.7437956\ttotal: 18.4s\tremaining: 10.4s\n",
      "192:\tlearn: 13231178.5722327\ttotal: 18.5s\tremaining: 10.3s\n",
      "193:\tlearn: 13224626.1104612\ttotal: 18.6s\tremaining: 10.2s\n",
      "194:\tlearn: 13218118.2092566\ttotal: 18.7s\tremaining: 10.1s\n",
      "195:\tlearn: 13212084.9260179\ttotal: 18.8s\tremaining: 9.99s\n",
      "196:\tlearn: 13205943.4736145\ttotal: 18.9s\tremaining: 9.9s\n",
      "197:\tlearn: 13200100.4836083\ttotal: 19s\tremaining: 9.8s\n",
      "198:\tlearn: 13194036.8395523\ttotal: 19.2s\tremaining: 9.72s\n",
      "199:\tlearn: 13188422.4988051\ttotal: 19.3s\tremaining: 9.63s\n",
      "200:\tlearn: 13182336.0356213\ttotal: 19.3s\tremaining: 9.53s\n",
      "201:\tlearn: 13176714.0003055\ttotal: 19.4s\tremaining: 9.43s\n",
      "202:\tlearn: 13171244.8031114\ttotal: 19.5s\tremaining: 9.34s\n",
      "203:\tlearn: 13165974.2144511\ttotal: 19.6s\tremaining: 9.24s\n",
      "204:\tlearn: 13160829.7152225\ttotal: 19.7s\tremaining: 9.14s\n",
      "205:\tlearn: 13155225.7997654\ttotal: 19.8s\tremaining: 9.04s\n",
      "206:\tlearn: 13149870.3405281\ttotal: 19.9s\tremaining: 8.94s\n",
      "207:\tlearn: 13144790.5859298\ttotal: 20s\tremaining: 8.85s\n",
      "208:\tlearn: 13139374.8495837\ttotal: 20.1s\tremaining: 8.75s\n",
      "209:\tlearn: 13133749.8153028\ttotal: 20.2s\tremaining: 8.65s\n",
      "210:\tlearn: 13128555.3322326\ttotal: 20.3s\tremaining: 8.56s\n",
      "211:\tlearn: 13123540.1108753\ttotal: 20.4s\tremaining: 8.46s\n",
      "212:\tlearn: 13118395.8988300\ttotal: 20.5s\tremaining: 8.36s\n",
      "213:\tlearn: 13113498.9358614\ttotal: 20.6s\tremaining: 8.27s\n",
      "214:\tlearn: 13108720.2798239\ttotal: 20.7s\tremaining: 8.18s\n",
      "215:\tlearn: 13103881.4705932\ttotal: 20.8s\tremaining: 8.08s\n",
      "216:\tlearn: 13099169.4295331\ttotal: 20.9s\tremaining: 7.98s\n",
      "217:\tlearn: 13094441.7669351\ttotal: 21s\tremaining: 7.89s\n",
      "218:\tlearn: 13090178.7670877\ttotal: 21.1s\tremaining: 7.79s\n",
      "219:\tlearn: 13085983.2410380\ttotal: 21.2s\tremaining: 7.7s\n",
      "220:\tlearn: 13081007.3727311\ttotal: 21.3s\tremaining: 7.6s\n",
      "221:\tlearn: 13076110.7131271\ttotal: 21.4s\tremaining: 7.51s\n",
      "222:\tlearn: 13071558.3322134\ttotal: 21.5s\tremaining: 7.41s\n",
      "223:\tlearn: 13067106.2147738\ttotal: 21.6s\tremaining: 7.32s\n",
      "224:\tlearn: 13062716.9767706\ttotal: 21.7s\tremaining: 7.22s\n",
      "225:\tlearn: 13058764.9978784\ttotal: 21.8s\tremaining: 7.12s\n",
      "226:\tlearn: 13054823.2815971\ttotal: 21.9s\tremaining: 7.03s\n",
      "227:\tlearn: 13050809.7894862\ttotal: 22s\tremaining: 6.93s\n",
      "228:\tlearn: 13046341.6554852\ttotal: 22.1s\tremaining: 6.84s\n",
      "229:\tlearn: 13043090.6615443\ttotal: 22.2s\tremaining: 6.75s\n",
      "230:\tlearn: 13039312.1002564\ttotal: 22.3s\tremaining: 6.65s\n",
      "231:\tlearn: 13035513.9008585\ttotal: 22.4s\tremaining: 6.55s\n",
      "232:\tlearn: 13031636.8433428\ttotal: 22.5s\tremaining: 6.46s\n",
      "233:\tlearn: 13027940.5208140\ttotal: 22.6s\tremaining: 6.36s\n",
      "234:\tlearn: 13024534.3410325\ttotal: 22.7s\tremaining: 6.26s\n",
      "235:\tlearn: 13020535.1203308\ttotal: 22.7s\tremaining: 6.17s\n",
      "236:\tlearn: 13016442.2099345\ttotal: 22.8s\tremaining: 6.07s\n",
      "237:\tlearn: 13013065.4178820\ttotal: 22.9s\tremaining: 5.97s\n",
      "238:\tlearn: 13009525.9785078\ttotal: 23s\tremaining: 5.87s\n",
      "239:\tlearn: 13006350.4229542\ttotal: 23.1s\tremaining: 5.77s\n",
      "240:\tlearn: 13003085.1513802\ttotal: 23.2s\tremaining: 5.67s\n",
      "241:\tlearn: 12999838.2784391\ttotal: 23.3s\tremaining: 5.58s\n",
      "242:\tlearn: 12996383.2285767\ttotal: 23.4s\tremaining: 5.48s\n",
      "243:\tlearn: 12993029.6023272\ttotal: 23.4s\tremaining: 5.38s\n",
      "244:\tlearn: 12989605.6043077\ttotal: 23.5s\tremaining: 5.28s\n",
      "245:\tlearn: 12985929.7530339\ttotal: 23.6s\tremaining: 5.18s\n",
      "246:\tlearn: 12982622.5190635\ttotal: 23.7s\tremaining: 5.09s\n",
      "247:\tlearn: 12979408.1355887\ttotal: 23.8s\tremaining: 4.99s\n",
      "248:\tlearn: 12975733.2202508\ttotal: 23.9s\tremaining: 4.89s\n",
      "249:\tlearn: 12972361.8332330\ttotal: 24s\tremaining: 4.79s\n",
      "250:\tlearn: 12968870.5064999\ttotal: 24.1s\tremaining: 4.7s\n",
      "251:\tlearn: 12965471.3947318\ttotal: 24.2s\tremaining: 4.6s\n",
      "252:\tlearn: 12962303.3843442\ttotal: 24.2s\tremaining: 4.5s\n",
      "253:\tlearn: 12959278.1508291\ttotal: 24.3s\tremaining: 4.41s\n",
      "254:\tlearn: 12956606.4679763\ttotal: 24.4s\tremaining: 4.31s\n",
      "255:\tlearn: 12953429.4485971\ttotal: 24.5s\tremaining: 4.21s\n",
      "256:\tlearn: 12950636.6023896\ttotal: 24.6s\tremaining: 4.12s\n",
      "257:\tlearn: 12947590.6954522\ttotal: 24.7s\tremaining: 4.03s\n",
      "258:\tlearn: 12944726.9266213\ttotal: 24.8s\tremaining: 3.93s\n",
      "259:\tlearn: 12942377.3842044\ttotal: 24.9s\tremaining: 3.83s\n",
      "260:\tlearn: 12939894.1673779\ttotal: 25s\tremaining: 3.74s\n",
      "261:\tlearn: 12937470.1049553\ttotal: 25.1s\tremaining: 3.64s\n",
      "262:\tlearn: 12934879.8653321\ttotal: 25.2s\tremaining: 3.54s\n",
      "263:\tlearn: 12931764.2070633\ttotal: 25.3s\tremaining: 3.44s\n",
      "264:\tlearn: 12928599.1386551\ttotal: 25.4s\tremaining: 3.35s\n",
      "265:\tlearn: 12925565.0364876\ttotal: 25.4s\tremaining: 3.25s\n",
      "266:\tlearn: 12923017.0995665\ttotal: 25.5s\tremaining: 3.15s\n",
      "267:\tlearn: 12920516.6246169\ttotal: 25.6s\tremaining: 3.06s\n",
      "268:\tlearn: 12917773.7284139\ttotal: 25.7s\tremaining: 2.96s\n",
      "269:\tlearn: 12915347.2176627\ttotal: 25.8s\tremaining: 2.87s\n",
      "270:\tlearn: 12912924.5355130\ttotal: 25.9s\tremaining: 2.77s\n",
      "271:\tlearn: 12909775.0799677\ttotal: 26s\tremaining: 2.68s\n",
      "272:\tlearn: 12907753.5939646\ttotal: 26.1s\tremaining: 2.58s\n",
      "273:\tlearn: 12905568.1835618\ttotal: 26.2s\tremaining: 2.48s\n",
      "274:\tlearn: 12903063.0268149\ttotal: 26.3s\tremaining: 2.39s\n",
      "275:\tlearn: 12901073.1065654\ttotal: 26.4s\tremaining: 2.29s\n",
      "276:\tlearn: 12897938.1790915\ttotal: 26.4s\tremaining: 2.19s\n",
      "277:\tlearn: 12895670.9366446\ttotal: 26.5s\tremaining: 2.1s\n",
      "278:\tlearn: 12893471.4410770\ttotal: 26.6s\tremaining: 2s\n",
      "279:\tlearn: 12890910.7794313\ttotal: 26.7s\tremaining: 1.91s\n",
      "280:\tlearn: 12888648.2472245\ttotal: 26.8s\tremaining: 1.81s\n",
      "281:\tlearn: 12886516.3339386\ttotal: 26.9s\tremaining: 1.72s\n",
      "282:\tlearn: 12884428.0500757\ttotal: 27s\tremaining: 1.62s\n",
      "283:\tlearn: 12881821.3627357\ttotal: 27.1s\tremaining: 1.53s\n",
      "284:\tlearn: 12879912.0513702\ttotal: 27.2s\tremaining: 1.43s\n",
      "285:\tlearn: 12877890.3655972\ttotal: 27.3s\tremaining: 1.33s\n",
      "286:\tlearn: 12875307.5452088\ttotal: 27.4s\tremaining: 1.24s\n",
      "287:\tlearn: 12872532.3662459\ttotal: 27.5s\tremaining: 1.14s\n",
      "288:\tlearn: 12869965.1474143\ttotal: 27.6s\tremaining: 1.05s\n",
      "289:\tlearn: 12867240.5789556\ttotal: 27.7s\tremaining: 954ms\n",
      "290:\tlearn: 12865078.7388991\ttotal: 27.8s\tremaining: 859ms\n",
      "291:\tlearn: 12862847.1426604\ttotal: 27.9s\tremaining: 763ms\n",
      "292:\tlearn: 12860539.5272386\ttotal: 27.9s\tremaining: 668ms\n",
      "293:\tlearn: 12858169.1109541\ttotal: 28s\tremaining: 572ms\n",
      "294:\tlearn: 12856093.4294279\ttotal: 28.1s\tremaining: 477ms\n",
      "295:\tlearn: 12854071.2436778\ttotal: 28.2s\tremaining: 382ms\n",
      "296:\tlearn: 12852229.3950958\ttotal: 28.3s\tremaining: 286ms\n",
      "297:\tlearn: 12850182.2289826\ttotal: 28.4s\tremaining: 191ms\n",
      "298:\tlearn: 12847879.1985405\ttotal: 28.5s\tremaining: 95.4ms\n",
      "299:\tlearn: 12845674.4845743\ttotal: 28.6s\tremaining: 0us\n",
      "RMSE: 12945927.473703556\n"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "\n",
    "model = cb.CatBoostRegressor(n_estimators=300\n",
    "                             , max_depth=10, random_state=42, learning_rate=0.01)\n",
    "model.fit(X_train, y_train, verbose=1)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lightgbm regressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMRegressor(n_estimators=340, max_depth=11, random_state=42, learning_rate=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gradient boosting regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=19, max_depth=10, random_state=42, verbose=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "val_predictions = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Nadam\n",
    "from keras.optimizers import legacy\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dropout(0.2))  # Apply dropout with a rate of 0.2\n",
    "# model.add(Dense(128, activation='relu'))#sigmoid\n",
    "# model.add(Dense(128, activation='relu'))#sigmoid\n",
    "\n",
    "model.add(Dense(64, activation='relu'))#sigmoid\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Add regularizers to the dense layers\n",
    "model.layers[1].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "model.layers[2].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "# model.layers[3].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "# model.layers[4].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "#model.layers[3].kernel_regularizer = regularizers.l1(0.001)  # Apply L2 regularization with a factor of 0.01\n",
    "\n",
    "optimizers = {\n",
    "    \"SGD\": SGD(learning_rate=0.01, momentum=0.9),\n",
    "    \"RMSprop\": RMSprop(learning_rate=0.01, rho=0.9),\n",
    "    \"Adagrad\": Adagrad(learning_rate=0.01),\n",
    "    \"Adadelta\": Adadelta(learning_rate=1.0, rho=0.95),\n",
    "    \"Nadam\": Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "}\n",
    "\n",
    "opt = legacy.Adam(learning_rate=0.001)  \n",
    "# opt = optimizers[\"RMSprop\"]\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['RootMeanSquaredError'])\n",
    "#apply early stoppping\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "#apply model checkpoint\n",
    "\n",
    "#fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_val, y_val), callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate rmse\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "print('Validation RMSE:', val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Create a DataFrame with 'row ID' and predictions\n",
    "result_df = pd.DataFrame({'row ID': row_ids, 'price_doc': test_predictions})\n",
    "\n",
    "result_df.to_csv('predictions_100.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
